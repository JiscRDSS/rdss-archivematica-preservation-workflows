# Background to the MVP Workflows 

When considering workflows that need to be supported in the MVP for digital preservation of research **Datasets**, we recognise that this may not be a top priority for the **Data Producers**, e.g. researchers, who create these Datasets.  For example, researchers typically want to get on with doing new research, publishing their results, collaborating with other researchers, getting citations and kudos, submitting successful grant applications etc.  

Researchers and Data Producers more generally should, in the ideal world, be very concerned about the long-term usability of their Datasets and actively want to do digital preservation.  This is a very real part part of making sure data is Findable, Accessible, Interoperable and Reusable [(FAIR)](http://www.nature.com/articles/sdata201618) and following good practice in many disciplines, e.g. Good Research Practice [(GRP)](https://www.mrc.ac.uk/publications/browse/good-research-practice-principles-and-guidelines/) for medical research.  It is also necessary to meet funding body requirements such as those stipulated by the [EPSRC](https://www.epsrc.ac.uk/about/standards/researchdata/expectations/), which in turn are based on the UK Research Councils (RCUK) [principles](http://www.rcuk.ac.uk/documents/documents/rcukcommonprinciplesondatapolicy-pdf/).  

However, in many cases, there is still a job of work to be done to educate and incentivise Data Producers to be more involved in the longeivity of their Datasets.  Therefore, in many insitutions the Data Producers expect that their host institution will take on the responsibility and activity of digital preservation, especially where digital preservation of Datasets is a complex activity and requires specialist skills and tools.  

As a result, our starting point for the MVP workflows is a pragmatic one that reflects the real-world where the typical workflow in many institutions is for the Data Producer to be concerned with initial deposit and publication of a Dataset and the Institution's **Data Manager** to be concerned with the appraisal, preservation and long-term accessibility and usability of the Research Data.  

The MVP supports two workflows

### Automated preservation workflow

In some cases, an Institution will lack resources (staff, skills, budget, time) to do a comprehensive job of preserving all their Datasets and will instead want a low-cost, fully automated, 'black box' approach to digital preservation of their Dataset.  In a sense, they want a 'preservation sausage machine' whereby research data is fed in at one end and out of the other comes 'preservation packages' containing the research data in a form that is better described and structured for long-term retention and usability.  Several institutions see automated preservation as the default route for their research Datasets and want a fully automated workflow that doesn't require manual intervention.

### Interactive preservation workflow

In other cases, the Institution will want to work closely with both the Dataset and the Data Producer as part of an iterative process of quality control and digital preservation with the end result that the Dataset is better documented from a technical perspective, is transformed into more open formats, is validated as complete and correct, and is signed-off as being fit for long-term access.  This is a more interactive and resource intensive process than 'automated' preservation, but can yield better results and may be more appropriate for specific types of Dataset or institution.   Several institutions see interactive preservation to be more appropriate to non-research data, e.g. special collections or other high value material at their institution. 

### Which workflow to use?

The most appropriate workflow to use will depend on many factors, e.g. the experience an institution has with digital preservation, the resources at its disposal, the research discipline or type of data involved, the requirements of the research funder, the institutions policy and so on.  For example, the interactive preservation workflow will require some experience with digital preservation, potentially including how to use of some Archivematica's preservation planning features and how to configure its preservation pipeline.  On the otherhand, our aim for the automated preservation workflow is to preconfigure the settings so preservation can be done 'out of the box' to as great an extent as possible and with minimal if not zero user intervention during the preservation process.

Some institutions may want to use both workflows, e.g. bulk process some of the majority of the research Datasets using the 'sausage machine' approach whilst using the 'interactive workflow' for specific high value or problematic Datasets.


### Digital Preservation Capabilities

There are many standard ('out of the box') capabilities for digital preservation that are provided by Archivematica.  More information on Archivematica's capabilities is provided on the Digital Preservation Capabilities page.  Some of these features may need further work and integration with the RDSS for their full utility to be realised.  This is explored on the Beyond the MVP page.  With those caveats in mind, we'd still very much encourage pilot participants to explore these capabilities to help us better understand what work will be required to move to a Beta phase of the service and beyond. 


